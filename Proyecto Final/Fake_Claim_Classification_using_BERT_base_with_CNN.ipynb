{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake Claim Classification using BERT-base with CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qow2csNoRXmH"
      },
      "source": [
        "This is the code for the paper: https://arxiv.org/abs/2009.01047 \n",
        "\n",
        "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake Claim Classification\n",
        "\n",
        "The code is for the best performing model where the TEXT is passed into BERT-base and the output of the BERT-base is concatenated with EMO, SPC and SEN and then passed to the CNN. The model achieved the accuracy of 70% and F1 Macro Score of 0.6430\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN-a_xrximUl"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up35yUrQftzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6411e3a0-de2d-450d-bb65-16ec150d2e6e"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"train_final.csv\")\n",
        "df_test=pd.read_csv(\"test_final.csv\")\n",
        "df_valid=pd.read_csv(\"valid_final.csv\")\n",
        "print(\"before truncating size of data is :\", df.shape, df_test.shape,df_valid.shape)\n",
        "df=df[:10232]\n",
        "df_test=df_test[:1264]\n",
        "df_valid=df_valid[:1280]\n",
        "print(\"size of data is :\", df.shape, df_test.shape, df_valid.shape)\n",
        "\n",
        "\n",
        "#check if any null values are present\n",
        "print(\"Any null in Subject? \",df['subject'].isnull().values.any())\n",
        "print(\"Any null in Speaker? \",df['speaker'].isnull().values.any())\n",
        "print(\"Any null in speaker_job? \",df['speaker_job'].isnull().values.any())\n",
        "print(\"Any null in Party? \",df['party_affiliation'].isnull().values.any())\n",
        "print(\"Any null in Context? \",df['context'].isnull().values.any())\n",
        "\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before truncating size of data is : (10236, 31) (1267, 30) (1283, 31)\n",
            "size of data is : (10232, 31) (1264, 30) (1280, 31)\n",
            "Any null in Subject?  False\n",
            "Any null in Speaker?  False\n",
            "Any null in speaker_job?  True\n",
            "Any null in Party?  False\n",
            "Any null in Context?  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbkLPaPJNdwZ"
      },
      "source": [
        "df['comment_text']=\"\"\n",
        "df_test['comment_text']=\"\"\n",
        "df_valid[\"comment_text\"]=\"\"\n",
        "\n",
        "#combine all the columns into one for train, test and valid data\n",
        "\n",
        "df['comment_text']=df['subject'].astype(str)+ \". \"+ df[\"statement\"]+\\\n",
        "df['speaker_id'].astype(str)+\". \"+df['speaker_job'].astype(str)+\". \"+ df['party_affiliation'].astype(str)\\\n",
        "+\". \"+df['context'].astype(str)+\". \"+df['sentiment_code'].astype(str)\n",
        "\n",
        "\n",
        "df_test['comment_text']=df_test['subject'].astype(str)+ \". \"+ df_test[\"statement\"]+\". \"+\\\n",
        "df_test['speaker_id'].astype(str)+\". \"+df_test['speaker_job'].astype(str)+\". \"+ df_test['party_affiliation'].astype(str)\\\n",
        "+\". \"+df_test['context'].astype(str)+\". \"+df['sentiment_code'].astype(str)\n",
        "\n",
        "df_valid['comment_text']=df_valid['subject'].astype(str)+ \". \"+ df_valid[\"statement\"]+\\\n",
        "df_valid['speaker_id'].astype(str)+\". \"+df_valid['speaker_job'].astype(str)+\". \"+ df_valid['party_affiliation'].astype(str)\\\n",
        "+\". \"+df_valid['context'].astype(str)+\". \"+df_valid['sentiment_code'].astype(str)\n",
        "\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5OeqXDPF0C"
      },
      "source": [
        "#concatenate emotion, speakers' credit and sentiment score togehter\n",
        "df['emotion']=\"[\"+df['anger'].astype(str)+\",\"+df['disgust'].astype(str)+\",\"\\\n",
        "+df['fear'].astype(str)+\",\"+df['joy'].astype(str)+\",\"+df['sad'].astype(str)+\",\"+\\\n",
        "df[\"barely_true_counts\"].astype(str) +\",\"+ df[\"false_counts\"].astype(str)  +\",\"+\\\n",
        "df[\"half_true_counts\"].astype(str) + \",\"+df[\"mostly_true_counts\"].astype(str) +\",\"+ \\\n",
        "df[\"pants_on_fire_counts\"].astype(str)+\",\"+df[\"sentiment_score\"].astype(str)+\"]\"\n",
        "\n",
        "\n",
        "df_test['emotion']=\"[\"+df_test['anger'].astype(str)+\",\"+df_test['disgust'].astype(str)+\",\"\\\n",
        "+df_test['fear'].astype(str)+\",\"+df_test['joy'].astype(str)+\",\"+df_test['sad'].astype(str)\\\n",
        "+ \",\"+df_test[\"barely_true_counts\"].astype(str) + \",\"+ df_test[\"false_counts\"].astype(str) \\\n",
        "+\",\"+ df_test[\"half_true_counts\"].astype(str) +\",\"+ df_test[\"mostly_true_counts\"].astype(str)\\\n",
        "+\",\"+ df_test[\"pants_on_fire_counts\"].astype(str)+\",\"+df_test[\"sentiment_score\"].astype(str)+\"]\"\n",
        "\n",
        "\n",
        "df_valid['emotion']=\"[\"+df_valid['anger'].astype(str)+\",\"+df_valid['disgust'].astype(str)+\",\"\\\n",
        "+df_valid['fear'].astype(str)+\",\"+df_valid['joy'].astype(str)+\",\"+df_valid['sad'].astype(str)\\\n",
        "+ \",\"+df_valid[\"barely_true_counts\"].astype(str) + \",\"+ df_valid[\"false_counts\"].astype(str) \\\n",
        "+\",\"+ df_valid[\"half_true_counts\"].astype(str) +\",\"+ df_valid[\"mostly_true_counts\"].astype(str)\\\n",
        "+\",\"+ df_valid[\"pants_on_fire_counts\"].astype(str)+\",\"+df_valid[\"sentiment_score\"].astype(str)+\"]\"\n",
        "\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahybcBEujX-m"
      },
      "source": [
        "#target should be converted from string to the list\n",
        "import ast\n",
        "def convert_to_list(text):\n",
        "  return ast.literal_eval(text)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUfBrHd2jZ1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5e9dae2-2533-40a0-d730-4f9ec379c64c"
      },
      "source": [
        "for i in range(len(df[\"emotion\"])):\n",
        "  try:\n",
        "    df[\"emotion\"][i] = convert_to_list(df[\"emotion\"][i])\n",
        "  except:\n",
        "    print(i,\"====\",df[\"emotion\"][1])"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T-5ig6Pl-1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c1339f-c941-4041-f2e3-58c70ece385c"
      },
      "source": [
        "for i in range(len(df_test[\"emotion\"])):\n",
        "  try:\n",
        "    df_test[\"emotion\"][i]=convert_to_list(df_test[\"emotion\"][i])\n",
        "  except:\n",
        "    print(i,\"====\",df_test[\"emotion\"][i], type(df_test[\"emotion\"][i]))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsftiolVlznH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62843f3-1198-4431-d475-627fccb61ceb"
      },
      "source": [
        "for i in range(len(df_valid[\"emotion\"])):\n",
        "  try:\n",
        "    df_valid[\"emotion\"][i]=convert_to_list(df_valid[\"emotion\"][i])\n",
        "  except:\n",
        "    print(i,\"====\",df_valid[\"emotion\"][i], type(df_valid[\"emotion\"][i]))    "
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPBghNgoj_em"
      },
      "source": [
        "df['list']=df['list'].apply(convert_to_list)\n",
        "df_test['list']=df_test['list'].apply(convert_to_list)\n",
        "df_valid['list']=df_valid['list'].apply(convert_to_list)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-qrs8fBNgs-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "\n",
        "MAX_LEN = 300\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 8\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ship6a3Ed58i"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.comment_text = dataframe.comment_text\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "        #Add emotion list from dataframe\n",
        "        self.emotion=dataframe.emotion\n",
        "        self.dfID=dataframe.ID\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment_text = str(self.comment_text[index])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
        "            'emotion':torch.tensor(self.emotion[index], dtype=torch.float),\n",
        "            'dfID':self.dfID[index]\n",
        "        }"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1GDiaXWd8pu",
        "outputId": "9382a030-8700-44e3-bb13-5d164794668a"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 1\n",
        "train_dataset=df.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "test_dataset=df_test.sample(frac=train_size,random_state=200).reset_index(drop=True)\n",
        "valid_dataset=df_valid.sample(frac=1,random_state=200).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "print(\"VALID Dataset: {}\".format(valid_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)\n",
        "valid_set= CustomDataset(valid_dataset, tokenizer, MAX_LEN)\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': 8,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "valid_loader=DataLoader(valid_set,**test_params)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (10232, 33)\n",
            "TRAIN Dataset: (10232, 33)\n",
            "TEST Dataset: (1264, 32)\n",
            "VALID Dataset: (1280, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1Lye08is-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea4287a-ea71-44e9-f7af-c3f232deb0fe"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of BERT-base to get the final output for the model. \n",
        "from torch import nn\n",
        "\n",
        "class BERT_cnn_Class(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BERT_cnn_Class, self).__init__()\n",
        "        self.l1          = transformers.BertModel.from_pretrained('bert-base-uncased', return_dict = False)\n",
        "        self.l2          = torch.nn.Dropout(0.3)\n",
        "        \n",
        "        self.l3          = torch.nn.Conv1d(1, 50, kernel_size=20,stride=1)\n",
        "        self.l4          = torch.nn.Conv1d(50,100, kernel_size=20, stride=1)\n",
        "        self.max_pooling = nn.MaxPool1d(2)\n",
        "        self.l5          = torch.nn.Linear(18000, 768)\n",
        "        self.l6          = torch.nn.Linear(768, 2)\n",
        "    \n",
        "    def forward(self, ids, mask, token_type_ids,emotion):\n",
        "        _, output_1 = self.l1(ids, attention_mask = mask, token_type_ids = token_type_ids)\n",
        "        output_2    = self.l2(output_1) #output from bert\n",
        "        #feed into conv net\n",
        "        #first change the size to [8,1,768]        \n",
        "        output_2    = torch.cat((emotion,output_2),1) # concat the output of BERT with EMO+SPC+SEN\n",
        "        output_2    = output_2.unsqueeze(1)        \n",
        "        output_3    = self.l3(output_2)        \n",
        "        output_3    = self.max_pooling(output_3)\n",
        "        output_4    = self.l4(output_3)        \n",
        "        output_4    = self.max_pooling(output_4)\n",
        "        #change the shape to fit into linear function\n",
        "        output_4    = output_4.view(8,-1)\n",
        "        output_5    = self.l5(output_4)\n",
        "        output_6    = self.l6(output_5)        \n",
        "        return output_6\n",
        "\n",
        "model = BERT_cnn_Class()\n",
        "\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX2TQ-a4i8Sn",
        "outputId": "6930ca95-11da-45dd-89c7-ff3e1b583818"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERT_cnn_Class(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (l2): Dropout(p=0.3, inplace=False)\n",
              "  (l3): Conv1d(1, 50, kernel_size=(20,), stride=(1,))\n",
              "  (l4): Conv1d(50, 100, kernel_size=(20,), stride=(1,))\n",
              "  (max_pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (l5): Linear(in_features=18000, out_features=768, bias=True)\n",
              "  (l6): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgLoP_Wlivpl"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHTHyN8ljQx-"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWIiFvmuixkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874cc0a6-fb53-416c-df4b-02d722820686"
      },
      "source": [
        "#TRAIN THE MODEL\n",
        "val_losses=[]\n",
        "train_losses=[]\n",
        "accuracy_list=[]\n",
        "\n",
        "for epoch in range(2):\n",
        "  t0 = time.time()\n",
        "  model.train()\n",
        "  print(f\"\\t Epoch: {epoch}  is Started: \")\n",
        "  batch=0\n",
        "  train_loss=0\n",
        "  \n",
        "  for _,data in enumerate(training_loader, 0):\n",
        "      try:\n",
        "          ids            = data['ids'].to(device, dtype  = torch.long)\n",
        "          mask           = data['mask'].to(device, dtype = torch.long)\n",
        "          token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "          targets        = data['targets'].to(device, dtype = torch.float)\n",
        "          emotions       = data['emotion'].to(device,dtype  = torch.float)\n",
        "      except:\n",
        "          print(f\"some error at testing {batch}\")\n",
        "          print(data['dfID'] )\n",
        "      try:  \n",
        "        outputs = model(ids, mask, token_type_ids,emotions)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        train_loss += loss.item()\n",
        "        #print(f'{count} Loss:  {loss.item()}')\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batch+=1\n",
        "      except EOFError:\n",
        "        print(f\"{data['dfID']} error because of batch size-------->\", EOFError)\n",
        "        print(f\"some error at testing {batch}\")\n",
        "        print(data['dfID'] )\n",
        "  print(f\"   Epoch: {epoch} Train loss is :{train_loss/batch}\") \n",
        "  train_loss /=batch\n",
        "  train_losses.append(train_loss)    \n",
        "  print(f\"   Epoch {epoch} took: {format_time(time.time() - t0)} \\n\")\n",
        "\n",
        "  model.eval()\n",
        "  fin_targets=[]\n",
        "  fin_outputs=[]\n",
        "  with torch.no_grad():\n",
        "      val_loss, batch = 0, 1\n",
        "      for _, data in enumerate(testing_loader, 0):\n",
        "          ids            = data['ids'].to(device, dtype = torch.long)\n",
        "          mask           = data['mask'].to(device, dtype = torch.long)\n",
        "          token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "          targets        = data['targets'].to(device, dtype = torch.float)\n",
        "          emotions       = data['emotion'].to(device,dtype=torch.float)\n",
        "          batch          += 1\n",
        "          try:\n",
        "                        outputs = model(ids, mask, token_type_ids,emotions)\n",
        "                        loss = loss_fn(outputs, targets)\n",
        "                        val_loss+=loss.item()\n",
        "                        fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "                        fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "          except:\n",
        "            print(f\"some error at testing {batch}\")\n",
        "            print(data['dfID'] )\n",
        "\n",
        "      val_loss/=batch\n",
        "      val_losses.append(val_loss)\n",
        "  outputs=fin_outputs\n",
        "  outputs = np.array(outputs) >= 0.5\n",
        "  targets=fin_targets\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  accuracy_list.append(accuracy)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "  print(f\"Epoch: {epoch} - Accuracy on Testing Data Score = {accuracy}\")\n",
        "  print(f\"Epoch: {epoch} - F1 Score on Testing Data (Micro) = {f1_score_micro}\")\n",
        "  print(f\"Epoch: {epoch} - F1 Score on Testing Data (Macro) = {f1_score_macro}\")\n",
        "  print(f\"\\n \\t Epoch {epoch} : Train Loss (Training Data):{train_loss}, Validation Loss (Testing Data): {val_loss}\")\n",
        "  print(\"_________________________________________________\\n\")\n",
        "  #if train_loss > val_loss:\n",
        "  # torch.save(model.state_dict(), \"/content/drive/My Drive/Bibek/models_saved/w9p7\")\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Epoch: 0  is Started: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz_2TpwBYJbm"
      },
      "source": [
        "from pandas import DataFrame\n",
        "df=DataFrame(train_losses,columns=['train_losses'])\n",
        "df=DataFrame(val_losses,columns=['val_losses'])\n",
        "df.to_csv(\"w10_p4.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRL6AyaF4p8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "fc7a4b65-bd98-400a-e61a-28bf4fcb7871"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses, label=\"Training loss\")\n",
        "plt.plot(val_losses, label=\"Validation loss\")\n",
        "\n",
        "plt.xlabel('Epoch', fontsize=18)\n",
        "plt.ylabel('Losses', fontsize=16)\n",
        "plt.title('Training Loss VS Validation Loss', fontsize=15)\n",
        "\n",
        "plt.legend()\n",
        "plt.savefig('w10_p4-epoch1.eps')\n",
        "\n",
        "#plt.title(\"Losses\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6CHKx_ADfiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a84e34c7-f534-4a8e-8ede-14f5d5524492"
      },
      "source": [
        "#Test on validation data\n",
        "model.eval()\n",
        "fin_targets=[]\n",
        "fin_outputs=[]\n",
        "with torch.no_grad():\n",
        "    c=0\n",
        "    for _, data in enumerate(valid_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "        emotions=data['emotion'].to(device,dtype=torch.float)\n",
        "        c+=1\n",
        "        try:\n",
        "                      outputs = model(ids, mask, token_type_ids,emotions)\n",
        "                      fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "                      fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "        except EOFError:\n",
        "          print(f\"some error at {c}\",EOFError)\n",
        "outputs=fin_outputs\n",
        "outputs = np.array(outputs) >= 0.5\n",
        "targets=fin_targets\n",
        "accuracy = metrics.accuracy_score(targets, outputs)\n",
        "\n",
        "f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "print(f\"Epoch:  {epoch}, Accuracy Score on validation data = {accuracy}\")\n",
        "\n",
        "print(f\"Epoch:  {epoch}, F1 Score on Validation Data (Macro) = {f1_score_macro}\") \n",
        "print(\"____________________________________________________________\\n________________________________________________________________\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1, Accuracy Score on validation data = 0.678125\n",
            "Epoch:  1, F1 Score on Validation Data (Macro) = 0.6180125496972404\n",
            "____________________________________________________________\n",
            "________________________________________________________________\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW8omPTzpNaS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}